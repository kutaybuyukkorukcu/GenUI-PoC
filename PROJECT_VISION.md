# GenUI Platform - Vision & Progress

> **Last Updated:** December 6, 2025

## ğŸ¯ Vision

Build a **Generative UI middleware platform** - similar to [Thesys C1](https://thesys.dev) - that transforms LLM responses into beautiful, interactive UI components. Users bring their own LLM API keys (BYOK model), and we provide the "GenUI layer" that handles component selection, structured output, and rendering.

## ğŸ’¼ Business Model: BYOK (Bring Your Own Key)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER'S APPLICATION                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚  Frontend   â”‚  React/Vue/etc with our UI Component SDK          â”‚
â”‚  â”‚  (React)    â”‚  Renders: Card, Table, Chart, Form, List, etc.    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚         â”‚                                                            â”‚
â”‚         â–¼                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  GenUI API Middleware (THIS PROJECT)                        â”‚    â”‚
â”‚  â”‚  POST /v1/chat/completions (OpenAI-compatible)              â”‚    â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚    â”‚
â”‚  â”‚  â€¢ Receives user's LLM API key via header                   â”‚    â”‚
â”‚  â”‚  â€¢ Injects system prompts for UI component selection        â”‚    â”‚
â”‚  â”‚  â€¢ Parses structured <genui> JSON from LLM response         â”‚    â”‚
â”‚  â”‚  â€¢ Returns SSE stream with component data                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                                                            â”‚
â”‚         â”‚ User's API Key (X-LLM-API-Key header)                     â”‚
â”‚         â–¼                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  LLM Provider (User's account, User pays directly)          â”‚    â”‚
â”‚  â”‚  â€¢ OpenAI (GPT-4, etc.)                                     â”‚    â”‚
â”‚  â”‚  â€¢ Azure OpenAI                                              â”‚    â”‚
â”‚  â”‚  â€¢ Anthropic Claude (future)                                 â”‚    â”‚
â”‚  â”‚  â€¢ Google Gemini (future)                                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Revenue Model Options
1. **Subscription** - Monthly fee for API access (like Thesys)
2. **Usage-based** - Per-request pricing for GenUI processing
3. **Freemium** - Free tier with limits, paid for higher usage
4. **Enterprise** - Self-hosted licenses

### Why BYOK?
- **No LLM costs for us** - User manages their own API spend
- **Trust** - User's data goes directly to their LLM provider
- **Flexibility** - User can use any model/provider they prefer
- **Value prop** - We charge for the GenUI layer, not LLM access

---

## âœ… Current Implementation Status

### Phase 1: Core API (COMPLETE)

| Component | Status | Description |
|-----------|--------|-------------|
| OpenAI-compatible endpoint | âœ… Done | `POST /v1/chat/completions` |
| BYOK KernelFactory | âœ… Done | Creates Kernel from user's API key at runtime |
| Request/Response models | âœ… Done | `ChatCompletionRequest`, `ChatCompletionResponse` |
| SSE Streaming | âœ… Done | Real-time token streaming to frontend |
| System prompts | âœ… Done | `UIComponentPrompts.cs` - teaches LLM to output GenUI |
| Response parser | âœ… Done | `UIResponseParser.cs` - extracts `<genui>` JSON |
| Fallback config | âœ… Done | Uses `.env` Azure OpenAI if no header key |

### Phase 2: Frontend SDK (COMPLETE for PoC)

| Component | Status | Description |
|-----------|--------|-------------|
| SSE Hook | âœ… Done | `useSSEChat.ts` - handles streaming |
| Component Registry | âœ… Done | Maps componentType â†’ React component |
| Card Renderer | âœ… Done | Generic card with title, data, description |
| Table Renderer | âœ… Done | Dynamic columns, auto-derive from data |
| Chart Renderer | âœ… Done | Recharts integration |
| Thinking Indicator | âœ… Done | Shows LLM reasoning steps |
| Chat Interface | âœ… Done | Full chat UI with message history |

### Phase 3: Docker & DevEx (COMPLETE)

| Component | Status | Description |
|-----------|--------|-------------|
| Docker Compose | âœ… Done | Backend + Frontend containers |
| Hot Reload | âœ… Done | `dotnet watch` + Vite HMR |
| Health check | âœ… Done | `/health` endpoint |
| nginx proxy | âœ… Done | `/v1/*` â†’ backend |

---

## ğŸš§ What's Left to Build

### Phase 4: Production Readiness

| Component | Priority | Description |
|-----------|----------|-------------|
| Platform API Key middleware | High | Authenticate GenUI users (not LLM users) |
| Usage tracking/billing | High | Track requests per user for billing |
| Rate limiting | High | Prevent abuse |
| Redis session store | Medium | Persist conversation history |
| Multi-tenant isolation | Medium | User data separation |
| Error handling/retries | Medium | Graceful LLM failure handling |

### Phase 5: SDK Distribution

| Component | Priority | Description |
|-----------|----------|-------------|
| React SDK package | High | `@genui/react` npm package |
| Vue SDK | Medium | `@genui/vue` npm package |
| .NET client | Low | For .NET frontend apps |
| Documentation site | High | API docs, component gallery |

### Phase 6: Advanced Features

| Component | Priority | Description |
|-----------|----------|-------------|
| MCP (Model Context Protocol) | High | Connect to external tools/databases |
| Custom component schemas | Medium | User-defined components |
| Component theming | Medium | Custom styling/branding |
| Form submissions | Medium | Handle user input from forms |
| Multi-modal (images) | Low | Image generation/display |

---

## ğŸ—ï¸ Architecture

### Backend (.NET 9)
```
Controllers/
  â””â”€â”€ ChatCompletionsController.cs   # OpenAI-compatible API
Services/
  â”œâ”€â”€ KernelFactory.cs               # BYOK - creates kernels per request
  â””â”€â”€ GenerativeUI/
      â”œâ”€â”€ UIComponentPrompts.cs      # System prompts for LLM
      â”œâ”€â”€ UIResponseParser.cs        # Parses <genui> from response
      â””â”€â”€ GenerativeUIModels.cs      # Component prop types
Models/
  â””â”€â”€ OpenAI/                        # OpenAI-compatible DTOs
```

### Frontend (React + Vite)
```
client/src/
  â”œâ”€â”€ components/
  â”‚   â”œâ”€â”€ chat/                      # Chat interface
  â”‚   â”œâ”€â”€ renderers/                 # Component renderers
  â”‚   â”‚   â”œâ”€â”€ ComponentRegistry.tsx  # componentType â†’ Component map
  â”‚   â”‚   â”œâ”€â”€ CardRenderer.tsx
  â”‚   â”‚   â”œâ”€â”€ TableRenderer.tsx
  â”‚   â”‚   â”œâ”€â”€ ChartRenderer.tsx
  â”‚   â”‚   â””â”€â”€ ThinkingIndicator.tsx
  â”‚   â””â”€â”€ ui/                        # shadcn/ui primitives
  â”œâ”€â”€ hooks/
  â”‚   â””â”€â”€ useSSEChat.ts              # SSE streaming hook
  â””â”€â”€ services/
      â””â”€â”€ api.ts                     # API client
```

---

## ğŸ”‘ Key Files

| File | Purpose |
|------|---------|
| `Controllers/ChatCompletionsController.cs` | Main API - OpenAI-compatible with GenUI |
| `Services/KernelFactory.cs` | Creates Semantic Kernel from user's API key |
| `Services/GenerativeUI/UIComponentPrompts.cs` | System prompts that teach LLM to output UI |
| `Services/GenerativeUI/UIResponseParser.cs` | Extracts structured JSON from LLM response |
| `client/src/components/renderers/ComponentRegistry.tsx` | Maps component types to React renderers |
| `client/src/hooks/useSSEChat.ts` | Handles SSE streaming from backend |

---

## ğŸ“¡ API Reference

### Chat Completions
```http
POST /v1/chat/completions
Content-Type: application/json
X-LLM-API-Key: sk-xxx (optional, falls back to .env)

{
  "model": "gpt-4",
  "messages": [
    {"role": "user", "content": "Show me weather in NYC"}
  ],
  "stream": true
}
```

**Response (SSE):**
```
data: {"id":"...","choices":[{"delta":{"content":"token"}}]}
data: {"id":"...","choices":[{"delta":{"content":"token"}}]}
...
event: genui
data: {"thinking":[...],"content":[{"type":"component","componentType":"card","props":{...}}]}
data: [DONE]
```

### Health Check
```http
GET /health

{"status":"healthy","version":"1.0.0"}
```

---

## ğŸ® How to Run

```bash
# Start everything
docker compose up -d --build

# Frontend: http://localhost:5173
# Backend:  http://localhost:5001
# Health:   http://localhost:5001/health
```

---

## ğŸ¯ Success Criteria for MVP

1. âœ… User can send chat message via frontend
2. âœ… Backend uses user's LLM key (or fallback) to call LLM
3. âœ… LLM uses internet search to get real data
4. âœ… LLM outputs structured GenUI JSON
5. âœ… Backend parses and streams response
6. âœ… Frontend renders appropriate component (card, table, chart)
7. â³ Platform API key for authenticating GenUI users
8. â³ Usage tracking for billing

---

## ğŸ“Š Comparison with Thesys C1

| Feature | Thesys C1 | GenUI (This Project) |
|---------|-----------|----------------------|
| API Style | OpenAI-compatible | âœ… OpenAI-compatible |
| BYOK | Yes | âœ… Yes |
| Component Types | Card, List, Table, Chart, etc. | âœ… Same |
| SSE Streaming | Yes | âœ… Yes |
| React SDK | Yes (`@thesys/c1-react`) | â³ To package |
| MCP Support | Yes | â³ Planned |
| Multi-provider | OpenAI, Anthropic, etc. | âœ… OpenAI, Azure (more planned) |

---

## ğŸ—ºï¸ Roadmap

### Q1 2025
- [x] Core BYOK API
- [x] React component renderers
- [x] Docker deployment
- [ ] Platform API key middleware
- [ ] Usage tracking

### Q2 2025
- [ ] Publish `@genui/react` npm package
- [ ] MCP integration for external tools
- [ ] Documentation site
- [ ] Production deployment (Azure/AWS)

### Q3 2025
- [ ] Vue SDK
- [ ] Custom component schemas
- [ ] Enterprise self-hosted option
